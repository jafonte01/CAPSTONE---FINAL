{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Accuracy Scoring - making it for general use!\n",
    "\n",
    "def model_scoring(model, xtrain, ytrain, xtest, ytest, datasetname=['CIFAR-10', 'CIFAR-110']):\n",
    "    \n",
    "        time_start = time.time()\n",
    "        model.fit(xtrain, ytrain)\n",
    "        print('Training Score for {} on {} Class Labels is {}%'.format(str(model), datasetname,\n",
    "                                                                             round(model.history(xtrain, \n",
    "                                                                                                  ytrain)*100),2))\n",
    "        ypred = model.predict(xtest)\n",
    "        yacc = round((model.score(ytest, ypred)*100),2)\n",
    "            \n",
    "        print('{} Model Accuracy Score on {} Class Labels is: {}%'.format(str(model), y10acc))\n",
    "                                                                                    \n",
    "        total_time = time.time()-time_start\n",
    "            \n",
    "        return ypred, total_time, yacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A customized evaluator by yours truly\n",
    "\n",
    "import random\n",
    "\n",
    "def CNN_evaluation10(model, num_of_examples=3):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    # setting initial prediction\n",
    "    model.fit(xtrain10, ytrain10)\n",
    "    \n",
    "    history = model.fit(x10train, y10train,\n",
    "                    nb_epoch=1,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x10test, y10test))\n",
    "    \n",
    "    cnnscore = np.mean(history.history['val_acc'])\n",
    "    print('Accuracy Score for this CNN for CIFAR-10 dataset is: ', cnnscore)\n",
    "    \n",
    "    #------------------------------------------------------------------------------\n",
    "    \n",
    "    #training_loss = history.history['loss']\n",
    "    #test_loss = history.history['val_loss']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "  #  epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    " #   plt.plot(epoch_count, training_loss, 'r--')\n",
    " #   plt.plot(epoch_count, test_loss, 'b-')\n",
    " #   plt.legend(['Training Loss', 'Test Loss'])\n",
    " #   plt.xlabel('Epoch')\n",
    " #   plt.ylabel('Loss')\n",
    " #   plt.show()\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    \n",
    "    # gathering this for \n",
    "    ypred = model.predict(xtest10) \n",
    "    yprob = model.predict_proba(xtest10)\n",
    "    yprob = yprob[1]\n",
    "             \n",
    "   # need to find non-matching items\n",
    "    '''\n",
    "    Setup of function: I want to find two samples from a given y-test (y10 or y110) that do NOT match\n",
    "    two predicted values for the respective sample indicies.        \n",
    "    '''\n",
    "        \n",
    "    wrongpredindex1 = []    \n",
    "        \n",
    "        # can cut down here\n",
    "    for i in list(range(len(ytest10))):\n",
    "        if ytest10[i] != (ypred[i] & ypred[i+1]): # cheating way of getting two wrong samples\n",
    "            wrongpredindex1.append(i)\n",
    "            \n",
    "        \n",
    "    randindx1 = random.sample(wrongpredindex1, num_of_examples)\n",
    "    randindx2 = [i+1 for i in randindx1]\n",
    "              \n",
    "    for i in list(range(num_of_examples)):\n",
    "        \n",
    "        # getting sample array samples\n",
    "            \n",
    "        sampleactual = testdf.loc[testdf['Target Num'] == ytest10[randindx1[i]]].sample(n=1)\n",
    "        samplewrongpred1 = testdf.loc[testdf['Target Num'] == ypred[randindx1[i]]].sample(n=1)\n",
    "        samplewrongpred2 = testdf.loc[testdf['Target Num'] == ypred[randindx2[i]]].sample(n=1)\n",
    "        \n",
    "        # using array samples for plotting\n",
    "        \n",
    "        plotsize = len(num_of_examples)\n",
    "        \n",
    "        plt.subplot(plotsize,(plotsize*3),i)\n",
    "        plt.imshow(sampleactual['Image Array'][0])\n",
    "        plt.title('Actual Image:', testdf['Target Names'][0])\n",
    "            \n",
    "        plt.subplot(plotsize,(plotsize*3),i+1)\n",
    "        plt.imshow(samplewrongpred1)\n",
    "        plt.imshow(samplewrongpred1['Image Array'][0])\n",
    "        plt.title('Wrong Predicted Image1:', samplewrongpred1['Target Names'][0])\n",
    "            \n",
    "        plt.subplot(plotsize,(plotsize*3),i+2)\n",
    "        plt.imshow(samplewrongpred2)\n",
    "        plt.imshow(samplewrongpred2['Image Array'][0])\n",
    "        plt.title('Wrong Predicted Image2:', samplewrongpred2['Target Names'][0])\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "    print('The analysis on this is complete after {} seconds.'.format(time.time()-time_start))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # declaring same for cifar110\n",
    "\n",
    "def CNN_evaluation110(model, num_of_examples=3):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    # setting initial prediction\n",
    "    model.fit(xtrain110, ytrain110)\n",
    "    \n",
    "    history = model.fit(x110train, y110train,\n",
    "                    nb_epoch=1,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x110test, y110test))\n",
    "    \n",
    "    cnnscore = np.mean(history.history['val_acc'])\n",
    "    print('Accuracy Score for this CNN for CIFAR-110 dataset is: ', cnnscore)\n",
    "    \n",
    "    #------------------------------------------------------------------------------\n",
    "    \n",
    "    #training_loss = history.history['loss']\n",
    "    #test_loss = history.history['val_loss']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "   # epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "  #  plt.plot(epoch_count, training_loss, 'r--')\n",
    "  #  plt.plot(epoch_count, test_loss, 'b-')\n",
    "  #  plt.legend(['Training Loss', 'Test Loss'])\n",
    "  #  plt.xlabel('Epoch')\n",
    "  #  plt.ylabel('Loss')\n",
    " #   plt.show()\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    \n",
    "    # gathering this for \n",
    "    ypred = model.predict(xtest110) \n",
    "    yprob = model.predict_proba(xtest110)\n",
    "    yprob = yprob[1]\n",
    "             \n",
    "   # need to find non-matching items\n",
    "    '''\n",
    "    Setup of function: I want to find two samples from a given y-test (y10 or y110) that do NOT match\n",
    "    two predicted values for the respective sample indicies.        \n",
    "    '''\n",
    "        \n",
    "    wrongpredindex1 = []    \n",
    "        \n",
    "        # can cut down here\n",
    "    for i in list(range(len(ytest110))):\n",
    "        if ytest110[i] != (ypred[i] & ypred[i+1]): # cheating way of getting two wrong samples\n",
    "            wrongpredindex1.append(i)\n",
    "            \n",
    "        \n",
    "    randindx1 = random.sample(wrongpredindex1, num_of_examples)\n",
    "    randindx2 = [i+1 for i in randindx1]\n",
    "              \n",
    "    for i in list(range(num_of_examples)):\n",
    "        \n",
    "        # getting sample array samples\n",
    "            \n",
    "        sampleactual = testdf.loc[testdf['Target Num'] == ytest110[randindx1[i]]].sample(n=1)\n",
    "        samplewrongpred1 = testdf.loc[testdf['Target Num'] == ypred[randindx1[i]]].sample(n=1)\n",
    "        samplewrongpred2 = testdf.loc[testdf['Target Num'] == ypred[randindx2[i]]].sample(n=1)\n",
    "        \n",
    "        # using array samples for plotting\n",
    "        \n",
    "        plotsize = len(num_of_examples)\n",
    "        \n",
    "        plt.subplot(plotsize,(plotsize*3),i)\n",
    "        plt.imshow(sampleactual['Image Array'][0])\n",
    "        plt.title('Actual Image:', testdf['Target Names'][0])\n",
    "            \n",
    "        plt.subplot(plotsize,(plotsize*3),i+1)\n",
    "        plt.imshow(samplewrongpred1)\n",
    "        plt.imshow(samplewrongpred1['Image Array'][0])\n",
    "        plt.title('Wrong Predicted Image1:', samplewrongpred1['Target Names'][0])\n",
    "            \n",
    "        plt.subplot(plotsize,(plotsize*3),i+2)\n",
    "        plt.imshow(samplewrongpred2)\n",
    "        plt.imshow(samplewrongpred2['Image Array'][0])\n",
    "        plt.title('Wrong Predicted Image2:', samplewrongpred2['Target Names'][0])\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "    print('The analysis on this is complete after {} seconds.'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(ytest, ypred,classes=range(10),\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.get_cmap('Blues')):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(ytest, ypred)                       \n",
    "                          \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As part of this section ------ Setting up x and y...again\n",
    "\n",
    "# setting up x's\n",
    "# these are set - commented out as just for reference\n",
    "#x10train and x110train = X10trainflatagain.astype(float) /=255\n",
    "#x10test and x110test = X110trainflatagain.astype(float) /=255\n",
    "\n",
    "# PCA versions of X\n",
    "pca=PCA(n_components=59)\n",
    "X10reducedtrain = pca.fit_transform(x10train)\n",
    "X10reducedtest = pca.fit_transform(x10test)\n",
    "\n",
    "pca=PCA(n_components=51)\n",
    "X110reducedtrain = pca.fit_transform(x110train)\n",
    "X110reducedtest = pca.fit_transform(x110test)\n",
    "\n",
    "#-------------------------------------------------------\n",
    "\n",
    "# setting up y's\n",
    "y10train = df10_train['Target Labels']\n",
    "y10test = df10_test['Target Labels']\n",
    "\n",
    "y110train = df110train['Target Num']\n",
    "y110test = df110test['Target Num']\n",
    "\n",
    "# going to use it if I need it, but if the model works without it, then in my opinion that's fine too.\n",
    "ytrain110_classlabel = keras.utils.to_categorical(y110train, 110) # 110 classes, excluding superclass column!\n",
    "ytest110_classlabel = keras.utils.to_categorical(y110test, 110)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd CNN model\n",
    "# CNN model 3\n",
    "\n",
    "# contains batchnormalizations on each layer\n",
    "\n",
    "def cnnmostcomplex(num_cat):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D((32,3,3), kernel_size=2, activation=\"relu\", input_shape=(32,32,3), padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(Conv2D(16, 3, 3), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add((Conv2D(32, 3, 3)), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64), activation='relu')\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(110, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model 3\n",
    "\n",
    "# contains batchnormalizations on each layer\n",
    "# using sigmoid activation for output layer \n",
    "\n",
    "def cnnmostcomplex(num_cat):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D((8,3,3), kernel_size=2, padding=\"same\", activation=\"relu\",\n",
    "                     input_shape=(32,32,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(16, 3, 3), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add((Conv2D(32, 3, 3)), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64), activation='relu')\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_cat, activation=('sigmoid')))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dual y axis bar graph\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "N = 5\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax1.bar(x=modelnames, height=ax2.bar, width=width, color='r')\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Model Names')\n",
    "ax1.set_ylabel('Processing Time', color=color)\n",
    "ax1.bar(height='Processing Time', data=acctimeplotdf, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Model Accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax2.bar(height='Model Accuracy', data=acctimeplotdf, color=color, err=acclist10std)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Model Accuracies and Times Using the CIFAR-10 Dataset')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "#CIFAR-110 graph\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "N = 3\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects2 = ax1.bar(x=modelnames, height=ax2.bar, width=width, color='r')\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Model Names')\n",
    "ax1.set_ylabel('Processing Time', color=color)\n",
    "ax1.bar(height='Processing Time', data=acctimeplotdf110, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Model Accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax2.bar(height='Model Accuracy', data=acctimeplotdf110, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Model Accuracies and Times Using the CIFAR-110 Dataset')\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "plt.suptitle('Model Comparison between Datasets of Differing Sizes')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n",
    "\n",
    "print('CIFAR-10 average time and accuracy are: \\\n",
    "{} +/- {} seconds and {} +/- {}%'.format(round(timelist10avg,2), round(timelist10std,2), \n",
    "                                        round(acclist10avg, 2), round(acclist10std,2)))\n",
    "\n",
    "print('CIFAR-110 average time and accuracy are: \\\n",
    "{} +/- {} seconds and {} +/- {}%'.format(round(timelist110avg,2), round(timelist110std,2), \n",
    "                                        round(acclist110avg, 2), round(acclist110std,2)))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "    X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255.0\n",
    "    X_test /= 255.0\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "    # MLP\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_shape=(3072, )))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # training\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))\n",
    "\n",
    "    save_history(history, 'history.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/\n",
    "    \n",
    "    sklearn MLP (deep feed-forward)\n",
    "    convolutional \n",
    "    recurrent\n",
    "    \n",
    "    https://www.kaggle.com/hamishdickson/preprocessing-images-with-dimensionality-reduction\n",
    "    \n",
    "    \n",
    "    https://idyll.pub/post/dimensionality-reduction-293e465c2a3443e8941b016d/\n",
    "    \n",
    "    # you need to do unsupervised learning ---- look under the \"clustering\"\n",
    "    # section to see clustering of images, and sampling the clustering\n",
    "    #spectral clustering is good for image clustering as well....\n",
    "    \n",
    "    https://www.datacamp.com/community/tutorials/machine-learning-python\n",
    "    \n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign the predicted values to `predicted`\n",
    "predicted = svc_model.predict(X_test)\n",
    "\n",
    "# Zip together the `images_test` and `predicted` values in `images_and_predictions`\n",
    "images_and_predictions = list(zip(images_test, predicted))\n",
    "\n",
    "# For the first 4 elements in `images_and_predictions`\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    # Initialize subplots in a grid of 1 by 4 at positions i+1\n",
    "    plt.subplot(1, 4, index + 1)\n",
    "    # Don't show axes\n",
    "    plt.axis('off')\n",
    "    # Display images in all subplots in the grid\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    # Add a title to the plot\n",
    "    plt.title('Predicted: ' + str(prediction))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links\n",
    "\n",
    "https://www.learnopencv.com/image-classification-using-feedforward-neural-network-in-keras/\n",
    "    \n",
    "    https://www.peculiar-coding-endeavours.com/2018/mlp_vs_cnn/\n",
    "        \n",
    "        https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification/notebook    #Build-Model\n",
    "                \n",
    "                https://www.kaggle.com/ssrihari/keras-cnn-example-98-accuracy\n",
    "                    \n",
    "                    https://github.com/beerboaa/Color-Classification-CNN/blob/master/color_net_training.py\n",
    "                        \n",
    "                        https://www.youtube.com/playlist?list=PL7a0Gt9Qt8nLwsc7fXuRqEPQZRBOCHmhG\n",
    "                            \n",
    "                            https://github.com/study-groups/ds-projects/\n",
    "                                \n",
    "                                https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "    \n",
    "    https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample cnn (kernel size syntax is messed up!)\n",
    "\n",
    "# CNN model 3\n",
    "\n",
    "# contains batchnormalizations on each layer\n",
    "# using sigmoid activation for output layer \n",
    "\n",
    "def cnnmostcomplex(num_cat):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (3,3), padding=\"same\", activation=\"relu\",\n",
    "                     input_shape=(32,32,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(16, 3, 3), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add((Conv2D(32, 3, 3)), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3), activation='relu')\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64), activation='relu')\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_cat, activation=('sigmoid')))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "history = cnnmostcomplex(10).fit(xtrain10, ytrain10,\n",
    "                       nb_epoch=10,\n",
    "                       verbose=1,\n",
    "                       validation_data=(xtest10, ytest10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
