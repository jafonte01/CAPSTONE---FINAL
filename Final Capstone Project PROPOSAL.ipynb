{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Proposal\n",
    "\n",
    "## John A. Fonte\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction and Significance of Research\n",
    "\n",
    "Object detection, identification, and classification is an ever-growing task in the computer science industry. The applications of the inter-disciplinary field of so-called \"computer vision\" range from facial recognition to handwriting detection to automating censoring and redaction, not to mention the applicability of accurately indexing the innumerable amount of images on the internet.\n",
    "\n",
    "It is therefore of the utmost importance to create machine learning models that not only accurately classify objects, but to do so with optimized efficiency. This project aims to determine __which models achieve these two goals of accuracy and efficiency.__\n",
    "\n",
    "## Proposed Data Source\n",
    "\n",
    "The proposed image dataset is one compiled from the Canadian Institute for Advanced Research, with the help of the University of Toronto's Computer Science Department.  The dataset, called __CIFAR-10__, is an image classification dataset with 10 different classes - four are vehicles (airplane, automobile, ship, truck), and six are animals (bird, cat, deer, dog, frog, horse).\\*\n",
    "\n",
    "Image loading libraries such as _Pillow (\"PIL\")_ and _Pickle_ will be used to import the image data into the Python environment.  Luckily, with great thanks to CIFAR, the images are all uniform 32 x 32 pixel pictures, making reshaping and resolution adjusting unnecessary. This will save significant time in skipping past cumbersome data cleaning work.\n",
    "\n",
    "__Dataset Source:__\n",
    "\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "---\n",
    "---\n",
    "__\\*Note:__ CIFAR also offers a CIFAR-100, which contains 100 different classifications than CIFAR-10. Not surprisingly, this dataset is significantly larger and may prove to beneficial in training a model for a more general application of image classification. However, computational limitations on the computer terminal provided (as opposed to taking advantage with GoogleColab's GPU resources) result in a smaller classification dataset being more suitable, with still achieving the same aim of training an image classification model.\n",
    "\n",
    "## Anticipated Analysis and Project Challenges\n",
    "\n",
    "Image Classification is almost exclusively done through Artificial Neural Networks (ANNs). The nature of its architecture is conducive to parsing pixels of an image, reorganize and flatten them, and output probabilities of classification based on training. Specifically, Convolutional Neural Networks analyze the image in a more accurate manner through repeated convolutions.\n",
    "\n",
    "The exclusivity of ANNs when analyzing images may prove to be a limitation in examining an otherwise wide range of available machine learning models.  Anticipated ANNs to be used in this project will be basic feed-forward ANNs (also known as _Multi-Layer Perceptrons (MLP)_), Convolutional Neural Networks, and One-Layer Feedback/Recurrent Neural Networks. Typical classification models, including more sophisticated ones, are simply not designed to accommodate and handle image data. This is a resulting limitation and challenge for the project.\n",
    "\n",
    "While this is a list of only three distinct machine learning models, the experimentation of the architecture of each of these networks is the crux of this project. The number of nodes, the number of hidden layers, and the activation algorithms for each of these layers can be adjusted for accuracy and efficiency. More so, hybridized pipeline models, which contain hidden layers from different kinds of ANNs, may prove more accurate and/or efficient than the sum of its distinct neural network parts. For example, hybridized models may provide boosting bonuses of modified image data, which otherwise would not be the inputs for a more basic model.\n",
    "\n",
    "---\n",
    "\n",
    "John A. Fonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
