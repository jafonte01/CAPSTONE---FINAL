{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CIFAR-'110':\n",
    "## Image Superclass & Subclass Classification\n",
    "   \n",
    "> ### Final Capstone Project\n",
    "> ### John A. Fonte\n",
    "> __May 2019 <br>\n",
    "[Github](https://github.com/jafonte01)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. __Introduction__\n",
    "    - Significance of Research\n",
    "    - Statement of Problem to be Solved\n",
    "    - Explanation of Dataset\n",
    "<br><br>\n",
    "2. __Image Data Loading__\n",
    "    - Pixel-to-Dimension Array Transposition and additional cleaning/transformations\n",
    "    - Data batch load compilation, data class balancing\n",
    "    - DataFrame setup\n",
    "    - train/test split, data shuffling\n",
    "<br><br>\n",
    "2. __Data Exploration__\n",
    "    - Visualization of Sample Datapoints\n",
    "<br><br>\n",
    "3. __Data Preparation for Modeling__\n",
    "    - Dimensionality reduction\n",
    "    - Use MLP Classifier to demonstrate dimensionality reduction effect\n",
    "<br><br>\n",
    "4. __Unsupervised Learning__\n",
    "    - Spectral Clustering\n",
    "    - t-SNE modeling and comparison to PCA results\n",
    "<br><br>\n",
    "5. __Supervised Modeling__\n",
    "    - Scaling introduced into modeling pipeline if not already done in Part 3\n",
    "    - Inclusion & Application of Autoencoding\n",
    "    - MLP Classifier\n",
    "    - Random Forest\n",
    "    - Recurrent Neural Network\n",
    "    - Convolutional Neural Networks\n",
    "<br><br>\n",
    "6. __Conclusion__\n",
    "    - Final Analysis & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 1. Introduction\n",
    "\n",
    "### Significance of Research\n",
    "Object detection, identification, and classification is an ever-growing task in the computer science industry. The applications of the inter-disciplinary field of so-called \"computer vision\" range from facial recognition to handwriting detection to automating censoring and redaction, not to mention the applicability of accurately indexing the innumerable amount of images on the internet.\n",
    "\n",
    "It is therefore of the utmost importance to create machine learning models that not only accurately classify objects, but to do so with optimized efficiency. This project aims to determine which models achieve these two goals of accuracy and efficiency.\n",
    "\n",
    "__STATEMENT OF PROBLEM:__\n",
    "\n",
    "Which machine learning model provides the best accuracy/performance trade-off when classifying objects?\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of Original Datasets: CIFAR-10 and CIFAR 100\n",
    "\n",
    "The image dataset to be used here is a concatenation of two datasets: the _CIFAR-10_ and _CIFAR-100_. Both of these datasets are one compiled from the Canadian Institute for Advanced Research, with the help of the University of Toronto's Computer Science Department. CIFAR-10 is a 10-class image dataset - four classes being vehicles (airplane, automobile, ship, truck), and six animals (bird, cat, deer, dog, frog, horse). CIFAR-100 is a 100-class image dataset, with 20 classes being classified under 1 of 20 \"superclasses.\" CIFAR-10 contains 50000 training images and 10000 testing images, with a total of 6000 images per class. The CIFAR-100 dataset is the same size, thus a total of 600 images per class.\n",
    "\n",
    "### Explanation of this Dataset: \"CIFAR-110\"\n",
    "\n",
    "CIFAR-110 is the concatenation of these two datasets. However, because CIFAR-10 classes are 10x larger than those in CIFAR-100, the ten CIFAR-10 classes __will be cut down to 600 images each__ before being concatenated with the CIFAR-100 data. Moreover, because the CIFAR-10 data does not have superclasses, the ten classes will be manually assigned a superclass. __Here, 5 out of the 20 superclasses will be assigned 2 additional image classes.__ This slightly imbalances the class space within these 20 superclasses (as 5 superclasses will have 7 classes, while the remaining 15 superclasses will have only 5 classes). While this is an express bias to be taken into account, it is hypothesized that it will have a negligible effect on the accuracy of superclass classification.\n",
    "\n",
    "Training and testing dataset splitting will be retained. Furthermore, __CIFAR-10 will be kept as a separate dataset__ to compare machine learning model results between low class and high class image datasets.\n",
    "\n",
    "### Explanation of the Data\n",
    "\n",
    "Each image is in a 32 x 32 pixel format with RGB coloring (32 x 32 x (R-channelvalue + G-channelvalue + B-channelvalue) = 3072 values total). Each pixel color-channel-value ranges from 0 (darkest) to 255 (brightest). With great thanks to CIFAR, the images are all uniform 32 x 32 size. This means that _necessary_ reshaping and other transformations do not need to be done; HOWEVER, data array reshaping, as well as other non-necessary image adjustements (e.g., resolution adjustments) will be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 2. Loading Data\n",
    "\n",
    "Loading data is done from local machine. You _could_ cheat and do `from keras.datasets import cifar100 ... cifar100.load_data`, but explaining the steps of loading will be more important for purposes of creating CIFAR-110."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports to start\n",
    "\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Image & Data Loading imports\n",
    "import pickle\n",
    "import PIL\n",
    "\n",
    "# other imports (i.e., sklearn imports and keras layers) will be done ad hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting pandas parameters for easily visualization\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing image data as dict\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading image data\n",
    "\n",
    "# I *could* do a list.dir() loop, \n",
    "# but with only 6 batch files to load, this is easier.\n",
    "\n",
    "batch1 = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-10-batches-py/data_batch_1')\n",
    "batch2 = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-10-batches-py/data_batch_2')\n",
    "batch3 = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-10-batches-py/data_batch_3')\n",
    "batch4 = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-10-batches-py/data_batch_4')\n",
    "batch5 = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-10-batches-py/data_batch_5')\n",
    "\n",
    "batch_test = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-10-batches-py/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading cifar 100 image data\n",
    "batch100train = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-100-python/train')\n",
    "batch100test = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-100-python/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The relevant keys in these dictionaries \n",
    "for BOTH CIFAR-10 and CIFAR-100 are: \n",
    "1. b'labels' = target variable labels for each of the images \n",
    "2. b'data'   = numpy array of the 3072 values per image\n",
    "'''\n",
    "print(batch1.keys())\n",
    "\n",
    "'''\n",
    "CIFAR-100 splits 'labels' into two keys:\n",
    "1. b'coarse_labels' = superclass labels\n",
    "2. b'fine_labels'   = normal class labels\n",
    "'''\n",
    "batch100train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Data Setup\n",
    "\n",
    "To create CIFAR-110 _and_ retain CIFAR-10 for comparison analysis, we need to do the following:\n",
    "<br>\n",
    "1. __Combine CIFAR-10 data batches__\n",
    "   - Done through `np.concatenate`\n",
    "<br><br>\n",
    "2. __Set CIFAR-10 combined training batch as a DataFrame and testing batch as second DataFrame__\n",
    "   - These DataFrames are saved for CIFAR-10 analysis\n",
    "<br><br>\n",
    "3. __Basic DataFrame Adjustments__\n",
    "   - Create target variable names based on labels\n",
    "   - Transpose 1D numpy arrays into pixel-representation arrays\n",
    "<br><br>\n",
    "4. __Create training and testing DataFrame subsets__\n",
    "   - CIFAR-10 training and testing DataFrames will be kept for comparison analysis\n",
    "   - Subsets will need to be 10% of data per class to maintain class and size balancing\n",
    "   - datapoints for each class will need to be shuffled to yield a non-biased class subset\n",
    "<br><br>\n",
    "5. __Manually add Superclass feature to CIFAR-10 subset data__\n",
    "<br><br>\n",
    "6. __Create CIFAR-100 DataFrame__\n",
    "   - Same Process as Steps 2 and 3 above\n",
    "<br><br>\n",
    "7. __Concatenate subset DataFrames with CIFAR-100 to create CIFAR-110__\n",
    "\n",
    "---\n",
    "### 2.1 - 2.3. Setting up DataFrames\n",
    "\n",
    "Image data works off of numpy arrays, not pandas DataFrames. However, for simplicity and organizational purposes, we can maintain the arrays in a DataFrame format. In my humble opinion, inputting a labeled DataFrame column is clearer and more intuitive than np.array\\[datapoint index\\]\\[datapoint label index\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([6, 9, 4, 1, 2, 7, 8, 3, 5, 0])\n",
      "dict_values([1030, 981, 999, 974, 1032, 1001, 1025, 1016, 937, 1005])\n",
      "dict_keys([1, 6, 8, 3, 4, 0, 5, 2, 7, 9])\n",
      "dict_values([1007, 1008, 987, 995, 1010, 984, 988, 1010, 1026, 985])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Checking if each batch has equal amounts of each class in them.\n",
    "If it does have an equal amount, \n",
    "we can cut down the data by class more easily.\n",
    "'''\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "batch1list = batch1.get(b'labels')\n",
    "batch2list = batch2.get(b'labels')\n",
    "\n",
    "print(Counter(batch1list).keys())   # equivalent to list(set(batch1list))\n",
    "print(Counter(batch1list).values()) # counts the frequency of each key element\n",
    "\n",
    "print(Counter(batch2list).keys())  \n",
    "print(Counter(batch2list).values())\n",
    "\n",
    "# it looks like it is not evenly distributed,\n",
    "# so we will have to concatenate first, then sift through it\n",
    "# (The test batch is good though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1-2.2 Data Batch Concatentation and DataFrame setup\n",
    "\n",
    "concat_data = np.concatenate((batch1.get(b'data'), batch2.get(b'data'), \n",
    "                              batch3.get(b'data'), batch4.get(b'data'), batch5.get(b'data')), \n",
    "                             axis=0)\n",
    "\n",
    "concat_labels = np.concatenate((batch1.get(b'labels'), batch2.get(b'labels'), \n",
    "                              batch3.get(b'labels'), batch4.get(b'labels'), batch5.get(b'labels')), \n",
    "                             axis=0)\n",
    "\n",
    "dfcifar10_train = pd.DataFrame({'1D Pixel Arrays':pd.Series([i for i in concat_data]),\n",
    "                                'Target Labels':pd.Series(concat_labels)})\n",
    "\n",
    "dfcifar10_test = pd.DataFrame({'1D Pixel Arrays':pd.Series([i for i in batch_test.get(b'data')]),\n",
    "                              'Target Labels':pd.Series(batch_test.get(b'labels'))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1D Pixel Arrays</th>\n",
       "      <th>Target Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[59, 43, 50, 68, 98, 119, 139, 145, 149, 149, 131, 125, 142, 144, 137, 129, 137, 134, 124, 139, 139, 133, 136, 139, 152, 163, 168, 159, 158, 158, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[154, 126, 105, 102, 125, 155, 172, 180, 142, 111, 106, 109, 123, 127, 181, 217, 209, 166, 164, 158, 116, 102, 95, 90, 72, 60, 56, 77, 94, 91, 87,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         1D Pixel Arrays  \\\n",
       "0  [59, 43, 50, 68, 98, 119, 139, 145, 149, 149, 131, 125, 142, 144, 137, 129, 137, 134, 124, 139, 139, 133, 136, 139, 152, 163, 168, 159, 158, 158, ...   \n",
       "1  [154, 126, 105, 102, 125, 155, 172, 180, 142, 111, 106, 109, 123, 127, 181, 217, 209, 166, 164, 158, 116, 102, 95, 90, 72, 60, 56, 77, 94, 91, 87,...   \n",
       "\n",
       "   Target Labels  \n",
       "0              6  \n",
       "1              9  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample dataframe output\n",
    "dfcifar10_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'num_cases_per_batch': 10000,\n",
       " b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta10 = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-10-batches-py/batches.meta')\n",
    "meta10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 DataFrame data transformations\n",
    "# Adding real labels to dfcifar_train Target Labels\n",
    "# the numbering matches up with the labels ordered on the dataset website (and shown above)\n",
    "'''\n",
    "(Note: I discovered the meta files until *after* I created these mapping functions. \n",
    "Had I known, I wouldn't have wasted my time hand-writing out every class name!)\n",
    "'''\n",
    "\n",
    "def cifar10_target_label_mapping(target_label_list):\n",
    "    final_label_list = []\n",
    "    labeldict = {0:'Airplane', 1:'Automobile', 2:'Bird', 3:'Cat', 4:'Deer', 5:'Dog',\n",
    "                6:'Frog', 7:'Horse', 8:'Ship', 9:'Truck'}\n",
    "    \n",
    "    for label in target_label_list:\n",
    "        final_label_list.append(labeldict.get(label))\n",
    "        \n",
    "    return final_label_list\n",
    "\n",
    "# applying to datasets\n",
    "dfcifar10_train['Target Names'] = pd.Series(cifar10_target_label_mapping(dfcifar10_train['Target Labels']))\n",
    "dfcifar10_test['Target Names'] = pd.Series(cifar10_target_label_mapping(dfcifar10_test['Target Labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Array Transposition \n",
    "\n",
    "The shape of original arrays in the CIFAR dataset are 1-dimension. Such an array shape is inappropriate for Python image libraries, which require: (Width, Height, (Number of Color channels or \"1\")).\n",
    "\n",
    "Specifically here, the first 1024 values of the 1-dimensional array are red-channel values, the second 1024 green-channel values, and the last 1024 blue-channel values. We are able to use the numpy method `.transpose([x,y,z])` to reshape these values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([154, 126, 105, 102, 125, 155, 172, 180, 142, 111, 106, 109, 123,\n",
       "       127, 181, 217, 209, 166, 164, 158, 116, 102,  95,  90,  72,  60,\n",
       "        56,  77,  94,  91,  87,  79, 140, 145, 125, 124, 150, 152, 174,\n",
       "       178, 134, 110, 133, 163, 192, 218, 240, 245, 241, 238], dtype=uint8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single sample image pixel array to exemplify 1-dimensionality of original data\n",
    "\n",
    "samplearray = batch1.get(b'data')[1]\n",
    "samplearray[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Input Array Data\n",
    "\n",
    "def array_to_pixel_dimensionality_transposition(numarr):\n",
    "    transposed_list = []\n",
    "    \n",
    "    for singlearray in numarr:\n",
    "        singletransposed = singlearray.reshape(3,32,32).transpose([1, 2, 0])\n",
    "        transposed_list.append(singletransposed)\n",
    "        \n",
    "    return transposed_list\n",
    "\n",
    "# applying to datasets\n",
    "dfcifar10_train['Image Array'] = pd.Series(array_to_pixel_dimensionality_transposition(dfcifar10_train['1D Pixel Arrays']))\n",
    "dfcifar10_test['Image Array'] = pd.Series(array_to_pixel_dimensionality_transposition(dfcifar10_test['1D Pixel Arrays']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1D Pixel Arrays</th>\n",
       "      <th>Target Labels</th>\n",
       "      <th>Target Names</th>\n",
       "      <th>Image Array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[59, 43, 50, 68, 98, 119, 139, 145, 149, 149, 131, 125, 142, 144, 137, 129, 137, 134, 124, 139, 139, 133, 136, 139, 152, 163, 168, 159, 158, 158, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>Frog</td>\n",
       "      <td>[[[59, 62, 63], [43, 46, 45], [50, 48, 43], [68, 54, 42], [98, 73, 52], [119, 91, 63], [139, 107, 75], [145, 110, 80], [149, 117, 89], [149, 120, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[154, 126, 105, 102, 125, 155, 172, 180, 142, 111, 106, 109, 123, 127, 181, 217, 209, 166, 164, 158, 116, 102, 95, 90, 72, 60, 56, 77, 94, 91, 87,...</td>\n",
       "      <td>9</td>\n",
       "      <td>Truck</td>\n",
       "      <td>[[[154, 177, 187], [126, 137, 136], [105, 104, 95], [102, 101, 99], [125, 131, 139], [155, 166, 180], [172, 190, 210], [180, 199, 214], [142, 156,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         1D Pixel Arrays  \\\n",
       "0  [59, 43, 50, 68, 98, 119, 139, 145, 149, 149, 131, 125, 142, 144, 137, 129, 137, 134, 124, 139, 139, 133, 136, 139, 152, 163, 168, 159, 158, 158, ...   \n",
       "1  [154, 126, 105, 102, 125, 155, 172, 180, 142, 111, 106, 109, 123, 127, 181, 217, 209, 166, 164, 158, 116, 102, 95, 90, 72, 60, 56, 77, 94, 91, 87,...   \n",
       "\n",
       "   Target Labels Target Names  \\\n",
       "0              6         Frog   \n",
       "1              9        Truck   \n",
       "\n",
       "                                                                                                                                             Image Array  \n",
       "0  [[[59, 62, 63], [43, 46, 45], [50, 48, 43], [68, 54, 42], [98, 73, 52], [119, 91, 63], [139, 107, 75], [145, 110, 80], [149, 117, 89], [149, 120, ...  \n",
       "1  [[[154, 177, 187], [126, 137, 136], [105, 104, 95], [102, 101, 99], [125, 131, 139], [155, 166, 180], [172, 190, 210], [180, 199, 214], [142, 156,...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brief check to see adjustment to DataFrames\n",
    "dfcifar10_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brief check for array shape\n",
    "dfcifar10_train['Image Array'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample image of a Ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check to see if \"Image Array\" data actually corresponds to Image parameters\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "print('This is a sample image of a', dfcifar10_train['Target Names'][100])\n",
    "plt.imshow(dfcifar10_train['Image Array'][100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ We will not scale or transform the images at this time. The focus is on creating the four datasets: <br> \n",
    "dfcifar10_train, dfcifar10_test, dfcifar110_train, dfcifar110_test.\n",
    "\n",
    "---\n",
    "### 2.4-2.5 DataFrame Subset and Transfer\n",
    "To create dfcifar110, we need to take a subset of _each_ class with the length of that found in each class in CIFAR100 (to maintain balancing). In other words, the subset will be 10% of each class in dfcifar10_train and dfcifar10_test.\n",
    "\n",
    "There, we will add a new target variable - the \"superclass\" found in CIFAR-100 but not in CIFAR-10 - to the dfcifar10 train and test subsets.\n",
    "\n",
    "Before we concatenate this data with dfcifar100, we need to have the features match exactly. Therefore, we need to create columns for Target Names and Image Arrays. Also as a technical but important point, we need to account for the class labels overlapping with that found in dfcifar. We will have to adjust the labels to make sure all classes are distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating subset function\n",
    "def CIFAR10_balancedsubset(df, targetvariablelist):\n",
    "    \n",
    "    dfbalancedsubset = pd.DataFrame(columns=list(dfcifar10_train.columns))\n",
    "    \n",
    "    for targetclass in targetvariablelist.unique():             \n",
    "        subclass = df[targetvariablelist == targetclass].copy() # I personally use .copy() \n",
    "                                                                # all the time to avoid weird errors!!!!!\n",
    "        #creating subclass via df.sample()    \n",
    "        subclass = subclass.sample(frac=0.1, random_state=44)   # df.sample automatically shuffles the data for sampling!\n",
    "        dfbalancedsubset = pd.concat([dfbalancedsubset, subclass])\n",
    "                      \n",
    "    return dfbalancedsubset                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying function to dataframes\n",
    "df10trainsubset = CIFAR10_balancedsubset(dfcifar10_train, dfcifar10_train['Target Names'])\n",
    "df10testsubset = CIFAR10_balancedsubset(dfcifar10_test, dfcifar10_test['Target Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length check\n",
    "df10trainsubset.shape # cut 5000 images per class down to 500 images per class to match dfcifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Superclass datacolumn addition:\n",
    "\n",
    "def CIFAR10_superclass_mapping(target_label_list):\n",
    "    \n",
    "    final_label_list = []\n",
    "    final_label_num_list = []\n",
    "    \n",
    "    # I don't think I can do this any other way but manually...\n",
    "    \n",
    "    labeldict = {0:'Vehicles 1', 1:'Vehicles 2', 2:'Reptiles', 3:'Medium-Sized Mammals', \n",
    "                 4:'Large Omnivores & Herbivores', 5:'Medium-Sized Mammals',\n",
    "                6:'Reptiles', 7:'Large Omnivores & Herbivores', 8:'Vehicles 1', 9:'Vehicles 2'}\n",
    "    \n",
    "    # These Numeric Superclass values taken from original dataset\n",
    "    labelnumdict = {'Vehicles1':18, 'Vehicles2':19, 'Reptiles':15, \n",
    "                    'Large Omnivores & Herbivores':11, 'Medium-Sized Mammals':12}\n",
    "    \n",
    "    for label in target_label_list:\n",
    "        target_label = labeldict.get(label)\n",
    "        \n",
    "        final_label_list.append(target_label)\n",
    "        final_label_num_list.append(labelnumdict.get(target_label))\n",
    "        \n",
    "        # outputs TWO Lists (to be convereted into Pandas Series and added to respective dataframes)\n",
    "    return final_label_list, final_label_num_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying function to subset df's - again, generating two data columns\n",
    "\n",
    "df10trainsubset['Superclass Name'], df10trainsubset['Class Label'] = CIFAR10_superclass_mapping(df10trainsubset['Target Labels'])\n",
    "df10testsubset['Superclass Name'], df10testsubset['Class Label'] = CIFAR10_superclass_mapping(df10testsubset['Target Labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Creating the CIFAR-100 DataFrames\n",
    "\n",
    "We will repeat the same DataFrame creation steps for CIFAR-100. Doing this ensures the shape and characteristics of the CIFAR-100 DataFrame match up perfectly to those in the CIFAR-10 datasets. The reason why this is so important is for the concatenation step between the two DataFrames via `pd.concat`; if the shapes and characteristics are not exact, an error will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])\n",
      "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])\n"
     ]
    }
   ],
   "source": [
    "# checking the characteristics to import\n",
    "print(batch100train.keys())\n",
    "print(batch100test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realized I went a little out of order creating superclass names when there are none!\n",
    "# gotta set this up for CIFAR-100 input data ***before*** concatenation\n",
    "\n",
    "'''\n",
    "NOTE: \n",
    "I realized I could've created a second argument called ['a', 'b', 'c'] and compiled all the mapping\n",
    "into one function, with \"if 'b'\", map label names, \"if 'c'\", map superclases, etc.\n",
    "...but the code is already there. There's no performance lost by creating a new function, \n",
    "so I'm leaving it.\n",
    "'''\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "def CIFAR100_superclass_mapping(target_label_list):\n",
    "    \n",
    "    final_label_list = []\n",
    "    \n",
    "    # I don't think I can do this any other way but manually...again...\n",
    "    # tried to carry over as much as I could though!\n",
    "    \n",
    "    labeldict = {18:'Vehicles 1', 19:'Vehicles 2', 15:'Reptiles', 12:'Medium-Sized Mammals', \n",
    "                 11:'Large Omnivores & Herbivores', 5:'Household Electronic Devices',\n",
    "                6:'Household Furniture', 7:'Insects', 8:'Large Carnivores', 9:'Large Man-Made Outdoor Things',\n",
    "                0:'Aquatic Mammals', 1:'Fish', 2:'Flowers', 3:'Food Containers', 4:'Fruits & Vegetables',\n",
    "                10:'Large Natural Outdoor Scenes', 13:'Non-Insect Vertebrates', 14:'People', 16:'Small Mammals',\n",
    "                17:'Trees'}\n",
    "    \n",
    "    for label in target_label_list:\n",
    "        target_label = labeldict.get(label)\n",
    "        \n",
    "        final_label_list.append(target_label)\n",
    "        \n",
    "        # outputs TWO Lists (to be convereted into Pandas Series and added to respective dataframes)\n",
    "    return final_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying function\n",
    "\n",
    "batch100traincoarselabellist = CIFAR100_superclass_mapping(batch100train.get(b'coarse_labels'))\n",
    "batch100testcoarselabellist = CIFAR100_superclass_mapping(batch100test.get(b'coarse_labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DataFrames\n",
    "'''\n",
    "You will see I added '10' to the Target Label values. \n",
    "This was to ensure that there was no overlap in classification labels when adding 10 new classes labeled 0 to 9.\n",
    "'''\n",
    "\n",
    "dfcifar100_train = pd.DataFrame({'1D Pixel Arrays':pd.Series([i for i in batch100train.get(b'data')]),\n",
    "                                'Target Labels':pd.Series([i+10 for i in batch100train.get(b'fine_labels')]),\n",
    "                               'Superclass Name': pd.Series(batch100traincoarselabellist)})\n",
    "\n",
    "dfcifar100_test = pd.DataFrame({'1D Pixel Arrays':pd.Series([i for i in batch100test.get(b'data')]),\n",
    "                              'Target Labels':pd.Series([i+10 for i in batch100test.get(b'fine_labels')]),\n",
    "                              'Superclass Name': pd.Series(batch100testcoarselabellist)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding final datacolumn: transpositioned arrays\n",
    "\n",
    "dfcifar100_train['Image Array'] = pd.Series(array_to_pixel_dimensionality_transposition(dfcifar100_train['1D Pixel Arrays']))\n",
    "dfcifar100_test['Image Array'] = pd.Series(array_to_pixel_dimensionality_transposition(dfcifar100_test['1D Pixel Arrays']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1D Pixel Arrays', 'Target Labels', 'Superclass Name', 'Image Array']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfcifar100_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'fine_label_names', b'coarse_label_names'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'apple',\n",
       " b'aquarium_fish',\n",
       " b'baby',\n",
       " b'bear',\n",
       " b'beaver',\n",
       " b'bed',\n",
       " b'bee',\n",
       " b'beetle',\n",
       " b'bicycle',\n",
       " b'bottle']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta100 = unpickle('D:/Github/Data-Science-Bootcamp/CAPSTONE - FINAL/cifar-100-python/meta')\n",
    "print(meta100.keys())\n",
    "meta100.get(b'fine_label_names')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping Target Names to Target Labels\n",
    "# Note - however, that the superclass labels are in order, \n",
    "# so the functions are an accurate representation of that\n",
    "\n",
    "targetnames = list(meta100.get(b'fine_label_names'))\n",
    "targetnameappend = []\n",
    "\n",
    "for i in dfcifar100_train['Target Labels']:\n",
    "    i = i - 10 # gotta fix that again for this loop!\n",
    "    labelname = targetnames[i]\n",
    "    targetnameappend.append(labelname)\n",
    "\n",
    "dfcifar100_train['Target Names'] = pd.Series(targetnameappend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing same for cifar100test\n",
    "targetnameappend = []\n",
    "\n",
    "for i in dfcifar100_test['Target Labels']:\n",
    "    i = i - 10 # gotta fix that again for this loop!\n",
    "    labelname = targetnames[i]\n",
    "    targetnameappend.append(labelname)\n",
    "\n",
    "dfcifar100_test['Target Names'] = pd.Series(targetnameappend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 CIFAR-101 DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1D Pixel Arrays', 'Target Labels', 'Superclass Name', 'Image Array',\n",
      "       'Target Names'],\n",
      "      dtype='object')\n",
      "Index(['1D Pixel Arrays', 'Target Labels', 'Target Names', 'Image Array',\n",
      "       'Superclass Name', 'Class Label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# for the grand finale: CIFAR10 and CIFAR100 concatenation\n",
    "# again, have to make sure the columns match up\n",
    "\n",
    "print(dfcifar100_train.columns)\n",
    "print(df10trainsubset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data'])\n",
      "b'ng batch 1 of 1'\n"
     ]
    }
   ],
   "source": [
    "print(batch100test.keys())\n",
    "print(batch100test.get(b'batch_label')[5:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one final data column to add: class label\n",
    "\n",
    "dfcifar100_train['Class Label'] = pd.Series(batch100train.get(b'coarse_labels'))\n",
    "dfcifar100_test['Class Label'] = pd.Series(batch100test.get(b'coarse_labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's concat!\n",
    "\n",
    "df101train = pd.concat([dfcifar100_train, df10trainsubset], axis=0, sort=True, ignore_index=True).reset_index()\n",
    "df101test = pd.concat([dfcifar100_test, df10testsubset], axis=0, sort=True, ignore_index=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1D Pixel Arrays</th>\n",
       "      <th>Class Label</th>\n",
       "      <th>Image Array</th>\n",
       "      <th>Superclass Name</th>\n",
       "      <th>Target Labels</th>\n",
       "      <th>Target Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 231, 176, 237, 255, 255, 255, 255, 255, 252, 242, 229, ...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 25...</td>\n",
       "      <td>Large Omnivores &amp; Herbivores</td>\n",
       "      <td>29</td>\n",
       "      <td>b'cattle'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[255, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 252, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, ...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[[[255, 255, 255], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 25...</td>\n",
       "      <td>Reptiles</td>\n",
       "      <td>39</td>\n",
       "      <td>b'dinosaur'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  \\\n",
       "0      0   \n",
       "1      1   \n",
       "\n",
       "                                                                                                                                         1D Pixel Arrays  \\\n",
       "0  [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 231, 176, 237, 255, 255, 255, 255, 255, 252, 242, 229, ...   \n",
       "1  [255, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 252, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, ...   \n",
       "\n",
       "   Class Label  \\\n",
       "0         11.0   \n",
       "1         15.0   \n",
       "\n",
       "                                                                                                                                             Image Array  \\\n",
       "0  [[[255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 25...   \n",
       "1  [[[255, 255, 255], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 25...   \n",
       "\n",
       "                Superclass Name Target Labels Target Names  \n",
       "0  Large Omnivores & Herbivores            29    b'cattle'  \n",
       "1                      Reptiles            39  b'dinosaur'  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df101train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some points of data cleaning\n",
    "\n",
    "# I'm not sure how that index column got there...\n",
    "\n",
    "# (commented out because I already dropped it)\n",
    "#df101train.drop(columns='index', inplace=True) \n",
    "#df101test.drop(columns='index', inplace=True)\n",
    "\n",
    "# Cleaning the Target Names - Making it Look Pretty\n",
    "import re\n",
    "\n",
    "def label_cleaner(labellist):\n",
    "    for name in labellist:\n",
    "        name = name.decode(\"utf-8\") # originally in \"bytes\" datatype - could not do string cleaning that way\n",
    "        name = re.sub('b\\'', '', name)\n",
    "        name = re.sub('\\'', '', name)\n",
    "        name = name.capitalize()\n",
    "        \n",
    "        return name\n",
    "\n",
    "# apply to data column\n",
    "df101train['Target Names'] = label_cleaner(df101train['Target Names'])\n",
    "df101test['Target Names'] = label_cleaner(df101test['Target Names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another data cleaning point - reordering columns\n",
    "# easiest way to do this is to overwrite the dataframe variable\n",
    "\n",
    "df101train = df101train[['1D Pixel Arrays', 'Image Array', 'Target Names', \n",
    "                         'Target Labels', 'Superclass Name', 'Class Label']].copy()\n",
    "df101test = df101test[['1D Pixel Arrays', 'Image Array', 'Target Names', \n",
    "                         'Target Labels', 'Superclass Name', 'Class Label']].copy()\n",
    "\n",
    "# redoing stupid names\n",
    "\n",
    "df101train.rename(columns={'Target Labels':'Target Num', 'Class Label': 'Superclass Num'}, inplace=True)\n",
    "df101test.rename(columns={'Target Labels':'Target Num', 'Class Label': 'Superclass Num'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1D Pixel Arrays</th>\n",
       "      <th>Image Array</th>\n",
       "      <th>Target Names</th>\n",
       "      <th>Target Num</th>\n",
       "      <th>Superclass Name</th>\n",
       "      <th>Superclass Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 231, 176, 237, 255, 255, 255, 255, 255, 252, 242, 229, ...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 25...</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>29</td>\n",
       "      <td>Large Omnivores &amp; Herbivores</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[255, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 252, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, ...</td>\n",
       "      <td>[[[255, 255, 255], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 25...</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>39</td>\n",
       "      <td>Reptiles</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         1D Pixel Arrays  \\\n",
       "0  [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 231, 176, 237, 255, 255, 255, 255, 255, 252, 242, 229, ...   \n",
       "1  [255, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 252, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, 253, ...   \n",
       "\n",
       "                                                                                                                                             Image Array  \\\n",
       "0  [[[255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 255, 255], [255, 25...   \n",
       "1  [[[255, 255, 255], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 253, 253], [253, 25...   \n",
       "\n",
       "  Target Names Target Num               Superclass Name  Superclass Num  \n",
       "0       Cattle         29  Large Omnivores & Herbivores            11.0  \n",
       "1       Cattle         39                      Reptiles            15.0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df101train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a final data cleaning thing, we are going to shuffle ALL datasets to minimize any \n",
    "# bias from the order of the datapoints. We can do this via the previously used df.sample\n",
    "\n",
    "df101train = df101train.sample(frac=1, axis=0).reset_index(drop=True)\n",
    "df101test = df101test.sample(frac=1, axis=0).reset_index(drop=True)\n",
    "\n",
    "# CIFAR-10 datasets\n",
    "# taking this as an opportunity to change my bad variables\n",
    "df10_train = dfcifar10_train.sample(frac=1, axis=0).reset_index(drop=True)\n",
    "df10_test = dfcifar10_test.sample(frac=1, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Final Thing - Leaving the Data Split the Way It Is\n",
    "\n",
    "CIFAR's train/test split is 5/6 to 1/6. Normally, that split is far too imbalanced; over 80% should be more than enough to train a good classifier.^ Normally, I would concatenate the two sets together, and re-split 75/25. Of course, I would use sklearn's hyperparameter `stratify` to ensure that the proportions of the various classes between the two sets are maintained.\n",
    "\n",
    "However, if the purpose of this project is to find an _accurate_ and _efficient_ model, we should err on the side of caution. As such, I will leave the 5/6 // 1/6 proportion.\n",
    "\n",
    "---\n",
    "^ Another reason why I am leaving the split the way it is is because I do not for one second believe that my opinions on dataset splitting are better than the creators of this well-known and highly-curated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/\n",
    "    \n",
    "    sklearn MLP (deep feed-forward)\n",
    "    convolutional \n",
    "    recurrent\n",
    "    \n",
    "    https://www.kaggle.com/hamishdickson/preprocessing-images-with-dimensionality-reduction\n",
    "    \n",
    "    \n",
    "    https://idyll.pub/post/dimensionality-reduction-293e465c2a3443e8941b016d/\n",
    "    \n",
    "    # you need to do unsupervised learning ---- look under the \"clustering\"\n",
    "    # section to see clustering of images, and sampling the clustering\n",
    "    #spectral clustering is good for image clustering as well....\n",
    "    \n",
    "    https://www.datacamp.com/community/tutorials/machine-learning-python\n",
    "    \n",
    "    # Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Figure size in inches\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "\n",
    "# Add title\n",
    "fig.suptitle('Cluster Center Images', fontsize=14, fontweight='bold')\n",
    "\n",
    "# For all labels (0-9)\n",
    "for i in range(10):\n",
    "    # Initialize subplots in a grid of 2X5, at i+1th position\n",
    "    ax = fig.add_subplot(2, 5, 1 + i)\n",
    "    # Display images\n",
    "    ax.imshow(clf.cluster_centers_[i].reshape((8, 8)), cmap=plt.cm.binary)\n",
    "    # Don't show the axes\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more visualization - look into: isomap, lle, t-sne, kernel_PCA\n",
    "\n",
    "\n",
    "# Import `Isomap()`\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "# Create an isomap and fit the `digits` data to it\n",
    "X_iso = Isomap(n_neighbors=10).fit_transform(X_train)\n",
    "\n",
    "# Compute cluster centers and predict cluster index for each sample\n",
    "clusters = clf.fit_predict(X_train)\n",
    "\n",
    "# Create a plot with subplots in a grid of 1X2\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Predicted Versus Training Labels', fontsize=14, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "# Add scatterplots to the subplots \n",
    "ax[0].scatter(X_iso[:, 0], X_iso[:, 1], c=clusters)\n",
    "ax[0].set_title('Predicted Training Labels')\n",
    "ax[1].scatter(X_iso[:, 0], X_iso[:, 1], c=y_train)\n",
    "ax[1].set_title('Actual Training Labels')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
